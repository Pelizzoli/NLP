{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1EPGJJlqbL-BldDZmqxBgUwFqQb7G8t4N",
      "authorship_tag": "ABX9TyMyQk8HOQvOMZnk8JPXr3Ta",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pelizzoli/NLP/blob/main/Task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im3DG_Fnb-Iz"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Conv1D, Conv2D, MaxPooling2D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from tqdm import tqdm\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKt7YixkeSd5",
        "outputId": "377a7071-250f-47f8-f7fa-e0c71a1d59e1"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBXToY18gZyO"
      },
      "source": [
        "N_CLASSES = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-kpv-afGgmE"
      },
      "source": [
        "Change file locations form my drive to your drive else you wont be able to run the program. Make sure that the files are changed here else the program wont run correctly.\n",
        "\n",
        "In addition run each cell in order else it might mess up the run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMTmg21VcFoh"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/NLP Data Sets/train.csv')\n",
        "dev = pd.read_csv('/content/drive/MyDrive/NLP Data Sets/dev.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/NLP Data Sets/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "VyI5L6rUcF1Y",
        "outputId": "c6c853a8-8448-4c66-8ec3-d5aee498f08a"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>569179849518161920</td>\n",
              "      <td>@united you're good. Thank you!</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>569835751275433984</td>\n",
              "      <td>@AmericanAir way to ruin a vacation, my brothe...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>568588936852799488</td>\n",
              "      <td>@JetBlue yes thankfully! Catering just got her...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>569525116725567491</td>\n",
              "      <td>@USAirways The automated message isn't helpful...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>568807823187976193</td>\n",
              "      <td>@JetBlue I'm #MakingLoveOutofNothingAtAll on m...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11853</th>\n",
              "      <td>570123872168574976</td>\n",
              "      <td>@AmericanAir will not help us on the phone, at...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11854</th>\n",
              "      <td>570063683256242177</td>\n",
              "      <td>@USAirways has the worst customer service line...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11855</th>\n",
              "      <td>568032524749942784</td>\n",
              "      <td>@USAirways grades for this trip:\\n\\nFlight tim...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11856</th>\n",
              "      <td>569705813142409217</td>\n",
              "      <td>@united Thanks for the vague canned response t...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11857</th>\n",
              "      <td>569976114124349440</td>\n",
              "      <td>@united already did that at the airport and 12...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11858 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tweet_id  ... airline_sentiment\n",
              "0      569179849518161920  ...          positive\n",
              "1      569835751275433984  ...          negative\n",
              "2      568588936852799488  ...          positive\n",
              "3      569525116725567491  ...          negative\n",
              "4      568807823187976193  ...          positive\n",
              "...                   ...  ...               ...\n",
              "11853  570123872168574976  ...          negative\n",
              "11854  570063683256242177  ...          negative\n",
              "11855  568032524749942784  ...          negative\n",
              "11856  569705813142409217  ...          negative\n",
              "11857  569976114124349440  ...          negative\n",
              "\n",
              "[11858 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XztIdElKG4MG"
      },
      "source": [
        "Preprocessing stage.\n",
        "Tokenise the data set, stop words taken out, lemmanization, and convierted back into a string. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGaXV6tq7Ndv"
      },
      "source": [
        "def lemmaWord(word):\n",
        "    lemma = wordnet.morphy(word)\n",
        "    if lemma is not None:\n",
        "        return lemma\n",
        "    else:\n",
        "        return word\n",
        "\n",
        "def preprocess(text, lemma=True, gram=1, rmStop=True):\n",
        "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b|@\\w+|#', '', text, flags=re.MULTILINE)\n",
        "    tokens = word_tokenize(text)\n",
        "    new_tokens = ''\n",
        "    stoplist = stopwordEn if rmStop else []\n",
        "    for i in tokens:\n",
        "        i = i.lower()\n",
        "        if i.isalpha() and (i not in stoplist):\n",
        "            if lemma: i = lemmaWord(i)\n",
        "            new_tokens += str(i) + ' '\n",
        "    del tokens\n",
        "\n",
        "    # # tokens_series = pd.Series(new_tokens)\n",
        "    # arg = tf.convert_to_tensor(new_tokens, dtype=tf.string)\n",
        "\n",
        "    return new_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "3DpcOVbqw7Ay",
        "outputId": "1f35b422-fcdb-4acb-ec60-61082690a830"
      },
      "source": [
        "train['text'] = train['text'].apply(preprocess)\n",
        "dev['text'] = dev['text'].apply(preprocess)\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>569179849518161920</td>\n",
              "      <td>good thank</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>569835751275433984</td>\n",
              "      <td>way ruin vacation brother call night multiple ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>568588936852799488</td>\n",
              "      <td>yes thankfully catering get loading frustrate ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>569525116725567491</td>\n",
              "      <td>automate message helpful impossible speak huma...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>568807823187976193</td>\n",
              "      <td>makingloveoutofnothingatall brandloveaffair lax</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11853</th>\n",
              "      <td>570123872168574976</td>\n",
              "      <td>help us phone gate checkin book travel client ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11854</th>\n",
              "      <td>570063683256242177</td>\n",
              "      <td>worst customer service line call times today a...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11855</th>\n",
              "      <td>568032524749942784</td>\n",
              "      <td>grade trip flight timeliness cancel flightatio...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11856</th>\n",
              "      <td>569705813142409217</td>\n",
              "      <td>thanks vague can response address issue</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11857</th>\n",
              "      <td>569976114124349440</td>\n",
              "      <td>already airport hr late flightr still guy real...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11858 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tweet_id  ... airline_sentiment\n",
              "0      569179849518161920  ...          positive\n",
              "1      569835751275433984  ...          negative\n",
              "2      568588936852799488  ...          positive\n",
              "3      569525116725567491  ...          negative\n",
              "4      568807823187976193  ...          positive\n",
              "...                   ...  ...               ...\n",
              "11853  570123872168574976  ...          negative\n",
              "11854  570063683256242177  ...          negative\n",
              "11855  568032524749942784  ...          negative\n",
              "11856  569705813142409217  ...          negative\n",
              "11857  569976114124349440  ...          negative\n",
              "\n",
              "[11858 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G0TfCKMcF4E"
      },
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(train['airline_sentiment'])\n",
        "\n",
        "x_train = train['text']\n",
        "y_train = le.transform(train['airline_sentiment'])\n",
        "x_dev = dev['text']\n",
        "y_dev = le.transform(dev['airline_sentiment'])\n",
        "x_test = test['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTGrqhWFcF9o",
        "outputId": "c18d1ea4-4826-4484-e1a0-355cde6e25d1"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                              good thank \n",
              "1        way ruin vacation brother call night multiple ...\n",
              "2        yes thankfully catering get loading frustrate ...\n",
              "3        automate message helpful impossible speak huma...\n",
              "4         makingloveoutofnothingatall brandloveaffair lax \n",
              "                               ...                        \n",
              "11853    help us phone gate checkin book travel client ...\n",
              "11854    worst customer service line call times today a...\n",
              "11855    grade trip flight timeliness cancel flightatio...\n",
              "11856             thanks vague can response address issue \n",
              "11857    already airport hr late flightr still guy real...\n",
              "Name: text, Length: 11858, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvYGZxtncGAY",
        "outputId": "ef10b03a-57e4-409f-b104-85d9e62e466b"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 2, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84kB47BnN1ir"
      },
      "source": [
        "**Create a Vocabulary Index**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URI42RhecGC7"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(x_train).batch(128)\n",
        "vectorizer.adapt(text_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R94qyiOvcGFj",
        "outputId": "952f17e0-bbd9-4a9f-e9b0-f01903c90837"
      },
      "source": [
        "vectorizer.get_vocabulary()[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'flight', 'get', 'thanks']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfqBeHHEcGIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71ad5edd-db70-4f1c-8a86-9d74160fc43c"
      },
      "source": [
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))\n",
        "word_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " '[UNK]': 1,\n",
              " 'flight': 2,\n",
              " 'get': 3,\n",
              " 'thanks': 4,\n",
              " 'cancel': 5,\n",
              " 'delay': 6,\n",
              " 'service': 7,\n",
              " 'customer': 8,\n",
              " 'help': 9,\n",
              " 'time': 10,\n",
              " 'bag': 11,\n",
              " 'plane': 12,\n",
              " 'call': 13,\n",
              " 'amp': 14,\n",
              " 'us': 15,\n",
              " 'need': 16,\n",
              " 'hours': 17,\n",
              " 'hold': 18,\n",
              " 'would': 19,\n",
              " 'thank': 20,\n",
              " 'try': 21,\n",
              " 'still': 22,\n",
              " 'please': 23,\n",
              " 'one': 24,\n",
              " 'make': 25,\n",
              " 'ca': 26,\n",
              " 'airline': 27,\n",
              " 'back': 28,\n",
              " 'gate': 29,\n",
              " 'flightled': 30,\n",
              " 'hour': 31,\n",
              " 'phone': 32,\n",
              " 'say': 33,\n",
              " 'guy': 34,\n",
              " 'change': 35,\n",
              " 'fly': 36,\n",
              " 'take': 37,\n",
              " 'tell': 38,\n",
              " 'like': 39,\n",
              " 'late': 40,\n",
              " 'check': 41,\n",
              " 'know': 42,\n",
              " 'go': 43,\n",
              " 'today': 44,\n",
              " 'agent': 45,\n",
              " 'ticket': 46,\n",
              " 'miss': 47,\n",
              " 'wait': 48,\n",
              " 'waiting': 49,\n",
              " 'airport': 50,\n",
              " 'want': 51,\n",
              " 'could': 52,\n",
              " 'great': 53,\n",
              " 'u': 54,\n",
              " 'book': 55,\n",
              " 'way': 56,\n",
              " 'going': 57,\n",
              " 'problem': 58,\n",
              " 'never': 59,\n",
              " 'flying': 60,\n",
              " 'day': 61,\n",
              " 'weather': 62,\n",
              " 'tomorrow': 63,\n",
              " 'really': 64,\n",
              " 'min': 65,\n",
              " 'last': 66,\n",
              " 'even': 67,\n",
              " 'minutes': 68,\n",
              " 'see': 69,\n",
              " 'good': 70,\n",
              " 'pay': 71,\n",
              " 'people': 72,\n",
              " 'seat': 73,\n",
              " 'home': 74,\n",
              " 'hr': 75,\n",
              " 'issue': 76,\n",
              " 'dm': 77,\n",
              " 'first': 78,\n",
              " 'another': 79,\n",
              " 'new': 80,\n",
              " 'give': 81,\n",
              " 'work': 82,\n",
              " 'unite': 83,\n",
              " 'love': 84,\n",
              " 'email': 85,\n",
              " 'travel': 86,\n",
              " 'luggage': 87,\n",
              " 'experience': 88,\n",
              " 'let': 89,\n",
              " 'ever': 90,\n",
              " 'someone': 91,\n",
              " 'crew': 92,\n",
              " 'worst': 93,\n",
              " 'number': 94,\n",
              " 'getting': 95,\n",
              " 'due': 96,\n",
              " 'lost': 97,\n",
              " 'baggage': 98,\n",
              " 'trip': 99,\n",
              " 'reservation': 100,\n",
              " 'next': 101,\n",
              " 'yes': 102,\n",
              " 'passenger': 103,\n",
              " 'right': 104,\n",
              " 'use': 105,\n",
              " 'much': 106,\n",
              " 'days': 107,\n",
              " 'week': 108,\n",
              " 'two': 109,\n",
              " 'seats': 110,\n",
              " 'sitting': 111,\n",
              " 'response': 112,\n",
              " 'staff': 113,\n",
              " 'line': 114,\n",
              " 'hope': 115,\n",
              " 'best': 116,\n",
              " 'aa': 117,\n",
              " 'online': 118,\n",
              " 'refund': 119,\n",
              " 'boarding': 120,\n",
              " 'answer': 121,\n",
              " 'sent': 122,\n",
              " 'keep': 123,\n",
              " 'stick': 124,\n",
              " 'bad': 125,\n",
              " 'already': 126,\n",
              " 'sure': 127,\n",
              " 'jfk': 128,\n",
              " 'look': 129,\n",
              " 'better': 130,\n",
              " 'left': 131,\n",
              " 'system': 132,\n",
              " 'connection': 133,\n",
              " 'since': 134,\n",
              " 'long': 135,\n",
              " 'times': 136,\n",
              " 'care': 137,\n",
              " 'tonight': 138,\n",
              " 'flightr': 139,\n",
              " 'wo': 140,\n",
              " 'well': 141,\n",
              " 'appreciate': 142,\n",
              " 'update': 143,\n",
              " 'mile': 144,\n",
              " 'fleet': 145,\n",
              " 'think': 146,\n",
              " 'nothing': 147,\n",
              " 'find': 148,\n",
              " 'fleek': 149,\n",
              " 'come': 150,\n",
              " 'yet': 151,\n",
              " 'put': 152,\n",
              " 'website': 153,\n",
              " 'night': 154,\n",
              " 'jetblue': 155,\n",
              " 'follow': 156,\n",
              " 'board': 157,\n",
              " 'hotel': 158,\n",
              " 'morning': 159,\n",
              " 'booking': 160,\n",
              " 'arrive': 161,\n",
              " 'flt': 162,\n",
              " 'attendant': 163,\n",
              " 'dfw': 164,\n",
              " 'nice': 165,\n",
              " 'air': 166,\n",
              " 'ago': 167,\n",
              " 'upgrade': 168,\n",
              " 'rebooked': 169,\n",
              " 'rude': 170,\n",
              " 'info': 171,\n",
              " 'hang': 172,\n",
              " 'also': 173,\n",
              " 'lax': 174,\n",
              " 'happen': 175,\n",
              " 'do': 176,\n",
              " 'voucher': 177,\n",
              " 'frustrate': 178,\n",
              " 'connect': 179,\n",
              " 'class': 180,\n",
              " 'charge': 181,\n",
              " 'fix': 182,\n",
              " 'anything': 183,\n",
              " 'pilot': 184,\n",
              " 'show': 185,\n",
              " 'point': 186,\n",
              " 'fail': 187,\n",
              " 'disappoint': 188,\n",
              " 'contact': 189,\n",
              " 'add': 190,\n",
              " 'rep': 191,\n",
              " 'free': 192,\n",
              " 'business': 193,\n",
              " 'understand': 194,\n",
              " 'receive': 195,\n",
              " 'offer': 196,\n",
              " 'land': 197,\n",
              " 'finally': 198,\n",
              " 'claim': 199,\n",
              " 'talk': 200,\n",
              " 'pass': 201,\n",
              " 'awesome': 202,\n",
              " 'working': 203,\n",
              " 'option': 204,\n",
              " 'every': 205,\n",
              " 'app': 206,\n",
              " 'able': 207,\n",
              " 'wifi': 208,\n",
              " 'team': 209,\n",
              " 'start': 210,\n",
              " 'rebook': 211,\n",
              " 'ask': 212,\n",
              " 'leave': 213,\n",
              " 'employee': 214,\n",
              " 'credit': 215,\n",
              " 'person': 216,\n",
              " 'open': 217,\n",
              " 'anyone': 218,\n",
              " 'tweet': 219,\n",
              " 'looking': 220,\n",
              " 'sfo': 221,\n",
              " 'hear': 222,\n",
              " 'phl': 223,\n",
              " 'many': 224,\n",
              " 'helpful': 225,\n",
              " 'fee': 226,\n",
              " 'without': 227,\n",
              " 'suppose': 228,\n",
              " 'making': 229,\n",
              " 'early': 230,\n",
              " 'yesterday': 231,\n",
              " 'via': 232,\n",
              " 'status': 233,\n",
              " 'amaze': 234,\n",
              " 'seem': 235,\n",
              " 'ok': 236,\n",
              " 'break': 237,\n",
              " 'available': 238,\n",
              " 'always': 239,\n",
              " 'almost': 240,\n",
              " 'terrible': 241,\n",
              " 'stop': 242,\n",
              " 'sorry': 243,\n",
              " 'suck': 244,\n",
              " 'site': 245,\n",
              " 'rt': 246,\n",
              " 'ord': 247,\n",
              " 'name': 248,\n",
              " 'thx': 249,\n",
              " 'speak': 250,\n",
              " 'money': 251,\n",
              " 'departure': 252,\n",
              " 'instead': 253,\n",
              " 'friend': 254,\n",
              " 'hi': 255,\n",
              " 'family': 256,\n",
              " 'earlier': 257,\n",
              " 'southwest': 258,\n",
              " 'plan': 259,\n",
              " 'job': 260,\n",
              " 'gt': 261,\n",
              " 'extra': 262,\n",
              " 'dca': 263,\n",
              " 'schedule': 264,\n",
              " 'return': 265,\n",
              " 'reply': 266,\n",
              " 'chance': 267,\n",
              " 'year': 268,\n",
              " 'move': 269,\n",
              " 'buy': 270,\n",
              " 'actually': 271,\n",
              " 'full': 272,\n",
              " 'different': 273,\n",
              " 'though': 274,\n",
              " 'tarmac': 275,\n",
              " 'strand': 276,\n",
              " 'send': 277,\n",
              " 'la': 278,\n",
              " 'ground': 279,\n",
              " 'member': 280,\n",
              " 'direct': 281,\n",
              " 'dallas': 282,\n",
              " 'boston': 283,\n",
              " 'question': 284,\n",
              " 'poor': 285,\n",
              " 'policy': 286,\n",
              " 'kid': 287,\n",
              " 'company': 288,\n",
              " 'allow': 289,\n",
              " 'airway': 290,\n",
              " 'unacceptable': 291,\n",
              " 'ridiculous': 292,\n",
              " 'found': 293,\n",
              " 'vega': 294,\n",
              " 'snow': 295,\n",
              " 'respond': 296,\n",
              " 'reason': 297,\n",
              " 'message': 298,\n",
              " 'horrible': 299,\n",
              " 'everyone': 300,\n",
              " 'big': 301,\n",
              " 'oh': 302,\n",
              " 'happy': 303,\n",
              " 'chicago': 304,\n",
              " 'lose': 305,\n",
              " 'expect': 306,\n",
              " 'destinationdragons': 307,\n",
              " 'denver': 308,\n",
              " 'calling': 309,\n",
              " 'spend': 310,\n",
              " 'least': 311,\n",
              " 'card': 312,\n",
              " 'wife': 313,\n",
              " 'something': 314,\n",
              " 'request': 315,\n",
              " 'old': 316,\n",
              " 'american': 317,\n",
              " 'vacation': 318,\n",
              " 'month': 319,\n",
              " 'leaving': 320,\n",
              " 'half': 321,\n",
              " 'ewr': 322,\n",
              " 'confirm': 323,\n",
              " 'bos': 324,\n",
              " 'ur': 325,\n",
              " 'treat': 326,\n",
              " 'seriously': 327,\n",
              " 'reschedule': 328,\n",
              " 'far': 329,\n",
              " 'clt': 330,\n",
              " 'twitter': 331,\n",
              " 'stay': 332,\n",
              " 'provide': 333,\n",
              " 'enough': 334,\n",
              " 'complaint': 335,\n",
              " 'wrong': 336,\n",
              " 'taking': 337,\n",
              " 'sit': 338,\n",
              " 'past': 339,\n",
              " 'deal': 340,\n",
              " 'account': 341,\n",
              " 'thing': 342,\n",
              " 'san': 343,\n",
              " 'runway': 344,\n",
              " 'pick': 345,\n",
              " 'might': 346,\n",
              " 'desk': 347,\n",
              " 'coming': 348,\n",
              " 'mechanical': 349,\n",
              " 'maybe': 350,\n",
              " 'link': 351,\n",
              " 'food': 352,\n",
              " 'together': 353,\n",
              " 'hard': 354,\n",
              " 'destination': 355,\n",
              " 'charlotte': 356,\n",
              " 'twice': 357,\n",
              " 'three': 358,\n",
              " 'little': 359,\n",
              " 'end': 360,\n",
              " 'cause': 361,\n",
              " 'bc': 362,\n",
              " 'may': 363,\n",
              " 'le': 364,\n",
              " 'confirmation': 365,\n",
              " 'car': 366,\n",
              " 'away': 367,\n",
              " 'traveling': 368,\n",
              " 'things': 369,\n",
              " 'using': 370,\n",
              " 'terminal': 371,\n",
              " 'row': 372,\n",
              " 'lack': 373,\n",
              " 'idea': 374,\n",
              " 'guess': 375,\n",
              " 'drop': 376,\n",
              " 'awful': 377,\n",
              " 'possible': 378,\n",
              " 'hey': 379,\n",
              " 'given': 380,\n",
              " 'feel': 381,\n",
              " 'saying': 382,\n",
              " 'real': 383,\n",
              " 'place': 384,\n",
              " 'nyc': 385,\n",
              " 'mean': 386,\n",
              " 'life': 387,\n",
              " 'landing': 388,\n",
              " 'else': 389,\n",
              " 'route': 390,\n",
              " 'newark': 391,\n",
              " 'error': 392,\n",
              " 'depart': 393,\n",
              " 'cool': 394,\n",
              " 'computer': 395,\n",
              " 'around': 396,\n",
              " 'w': 397,\n",
              " 'thru': 398,\n",
              " 'quick': 399,\n",
              " 'plus': 400,\n",
              " 'houston': 401,\n",
              " 'deliver': 402,\n",
              " 'close': 403,\n",
              " 'soon': 404,\n",
              " 'price': 405,\n",
              " 'busy': 406,\n",
              " 'thought': 407,\n",
              " 'telling': 408,\n",
              " 'pls': 409,\n",
              " 'lot': 410,\n",
              " 'longer': 411,\n",
              " 'disconnect': 412,\n",
              " 'apology': 413,\n",
              " 'worse': 414,\n",
              " 'switch': 415,\n",
              " 'loyal': 416,\n",
              " 'international': 417,\n",
              " 'iad': 418,\n",
              " 'handle': 419,\n",
              " 'usairways': 420,\n",
              " 'second': 421,\n",
              " 'run': 422,\n",
              " 'process': 423,\n",
              " 'phx': 424,\n",
              " 'philly': 425,\n",
              " 'na': 426,\n",
              " 'lol': 427,\n",
              " 'cost': 428,\n",
              " 'carry': 429,\n",
              " 'bring': 430,\n",
              " 'believe': 431,\n",
              " 'ua': 432,\n",
              " 'standby': 433,\n",
              " 'hate': 434,\n",
              " 'forward': 435,\n",
              " 'fare': 436,\n",
              " 'everything': 437,\n",
              " 'easy': 438,\n",
              " 'city': 439,\n",
              " 'sat': 440,\n",
              " 'jet': 441,\n",
              " 'im': 442,\n",
              " 'fll': 443,\n",
              " 'figure': 444,\n",
              " 'rock': 445,\n",
              " 'minute': 446,\n",
              " 'maintenance': 447,\n",
              " 'information': 448,\n",
              " 'drive': 449,\n",
              " 'cust': 450,\n",
              " 'turn': 451,\n",
              " 'swa': 452,\n",
              " 'lga': 453,\n",
              " 'glad': 454,\n",
              " 'assistance': 455,\n",
              " 'world': 456,\n",
              " 'reflight': 457,\n",
              " 'iah': 458,\n",
              " 'fine': 459,\n",
              " 'dc': 460,\n",
              " 'counting': 461,\n",
              " 'address': 462,\n",
              " 'years': 463,\n",
              " 'worry': 464,\n",
              " 'share': 465,\n",
              " 'monday': 466,\n",
              " 'mess': 467,\n",
              " 'live': 468,\n",
              " 'joke': 469,\n",
              " 'human': 470,\n",
              " 'form': 471,\n",
              " 'entire': 472,\n",
              " 'correct': 473,\n",
              " 'concern': 474,\n",
              " 'case': 475,\n",
              " 'blue': 476,\n",
              " 'award': 477,\n",
              " 'refuse': 478,\n",
              " 'purchase': 479,\n",
              " 'child': 480,\n",
              " 'wish': 481,\n",
              " 'usair': 482,\n",
              " 'traveler': 483,\n",
              " 'supervisor': 484,\n",
              " 'record': 485,\n",
              " 'reach': 486,\n",
              " 'miami': 487,\n",
              " 'flyer': 488,\n",
              " 'den': 489,\n",
              " 'club': 490,\n",
              " 'cabin': 491,\n",
              " 'automate': 492,\n",
              " 'asap': 493,\n",
              " 'yeah': 494,\n",
              " 'whole': 495,\n",
              " 'upset': 496,\n",
              " 'unitedairlines': 497,\n",
              " 'tv': 498,\n",
              " 'room': 499,\n",
              " 'resolve': 500,\n",
              " 'group': 501,\n",
              " 'future': 502,\n",
              " 'explain': 503,\n",
              " 'empty': 504,\n",
              " 'delta': 505,\n",
              " 'date': 506,\n",
              " 'communication': 507,\n",
              " 'beyond': 508,\n",
              " 'asking': 509,\n",
              " 'watch': 510,\n",
              " 'sunday': 511,\n",
              " 'promise': 512,\n",
              " 'probably': 513,\n",
              " 'pretty': 514,\n",
              " 'kind': 515,\n",
              " 'holding': 516,\n",
              " 'force': 517,\n",
              " 'file': 518,\n",
              " 'fault': 519,\n",
              " 'ceo': 520,\n",
              " 'submit': 521,\n",
              " 'sleep': 522,\n",
              " 'sad': 523,\n",
              " 'report': 524,\n",
              " 'rather': 525,\n",
              " 'hopefully': 526,\n",
              " 'details': 527,\n",
              " 'cant': 528,\n",
              " 'bwi': 529,\n",
              " 'wow': 530,\n",
              " 'waste': 531,\n",
              " 'super': 532,\n",
              " 'sign': 533,\n",
              " 'running': 534,\n",
              " 'orlando': 535,\n",
              " 'nashville': 536,\n",
              " 'leg': 537,\n",
              " 'layover': 538,\n",
              " 'helping': 539,\n",
              " 'forget': 540,\n",
              " 'counter': 541,\n",
              " 'clothes': 542,\n",
              " 'sw': 543,\n",
              " 'space': 544,\n",
              " 'set': 545,\n",
              " 'medium': 546,\n",
              " 'luv': 547,\n",
              " 'lounge': 548,\n",
              " 'load': 549,\n",
              " 'list': 550,\n",
              " 'head': 551,\n",
              " 'gon': 552,\n",
              " 'either': 553,\n",
              " 'door': 554,\n",
              " 'completely': 555,\n",
              " 'companion': 556,\n",
              " 'austin': 557,\n",
              " 'atlanta': 558,\n",
              " 'apparently': 559,\n",
              " 'wonder': 560,\n",
              " 'transfer': 561,\n",
              " 'support': 562,\n",
              " 'screw': 563,\n",
              " 'safety': 564,\n",
              " 'ready': 565,\n",
              " 'post': 566,\n",
              " 'pm': 567,\n",
              " 'fast': 568,\n",
              " 'dont': 569,\n",
              " 'cross': 570,\n",
              " 'checkin': 571,\n",
              " 'access': 572,\n",
              " 'wtf': 573,\n",
              " 'trouble': 574,\n",
              " 'top': 575,\n",
              " 'okay': 576,\n",
              " 'means': 577,\n",
              " 'mco': 578,\n",
              " 'inconvenience': 579,\n",
              " 'giving': 580,\n",
              " 'flightlations': 581,\n",
              " 'currently': 582,\n",
              " 'country': 583,\n",
              " 'bump': 584,\n",
              " 'zero': 585,\n",
              " 'tuesday': 586,\n",
              " 'storm': 587,\n",
              " 'r': 588,\n",
              " 'notice': 589,\n",
              " 'note': 590,\n",
              " 'lots': 591,\n",
              " 'kudos': 592,\n",
              " 'fun': 593,\n",
              " 'daughter': 594,\n",
              " 'course': 595,\n",
              " 'continue': 596,\n",
              " 'compensation': 597,\n",
              " 'yr': 598,\n",
              " 'wonderful': 599,\n",
              " 'tsa': 600,\n",
              " 'surprise': 601,\n",
              " 'state': 602,\n",
              " 'situation': 603,\n",
              " 'shit': 604,\n",
              " 'services': 605,\n",
              " 'part': 606,\n",
              " 'middle': 607,\n",
              " 'lady': 608,\n",
              " 'huge': 609,\n",
              " 'high': 610,\n",
              " 'friendly': 611,\n",
              " 'extremely': 612,\n",
              " 'expire': 613,\n",
              " 'drink': 614,\n",
              " 'choice': 615,\n",
              " 'attitude': 616,\n",
              " 'atl': 617,\n",
              " 'aircraft': 618,\n",
              " 'winter': 619,\n",
              " 'true': 620,\n",
              " 'tag': 621,\n",
              " 'showing': 622,\n",
              " 'read': 623,\n",
              " 'priority': 624,\n",
              " 'must': 625,\n",
              " 'mom': 626,\n",
              " 'mileage': 627,\n",
              " 'lt': 628,\n",
              " 'learn': 629,\n",
              " 'front': 630,\n",
              " 'despite': 631,\n",
              " 'customerservice': 632,\n",
              " 'cold': 633,\n",
              " 'word': 634,\n",
              " 'weekend': 635,\n",
              " 'unfortunately': 636,\n",
              " 'unable': 637,\n",
              " 'tix': 638,\n",
              " 'several': 639,\n",
              " 'sending': 640,\n",
              " 'rdu': 641,\n",
              " 'overnight': 642,\n",
              " 'notification': 643,\n",
              " 'luck': 644,\n",
              " 'id': 645,\n",
              " 'husband': 646,\n",
              " 'haha': 647,\n",
              " 'gold': 648,\n",
              " 'friday': 649,\n",
              " 'following': 650,\n",
              " 'flightlation': 651,\n",
              " 'fill': 652,\n",
              " 'failure': 653,\n",
              " 'fact': 654,\n",
              " 'enjoy': 655,\n",
              " 'dividend': 656,\n",
              " 'control': 657,\n",
              " 'complete': 658,\n",
              " 'compensate': 659,\n",
              " 'yall': 660,\n",
              " 'works': 661,\n",
              " 'wall': 662,\n",
              " 'tire': 663,\n",
              " 'spoke': 664,\n",
              " 'social': 665,\n",
              " 'small': 666,\n",
              " 'sense': 667,\n",
              " 'sell': 668,\n",
              " 'original': 669,\n",
              " 'office': 670,\n",
              " 'multiple': 671,\n",
              " 'mine': 672,\n",
              " 'man': 673,\n",
              " 'letter': 674,\n",
              " 'ice': 675,\n",
              " 'however': 676,\n",
              " 'excite': 677,\n",
              " 'cs': 678,\n",
              " 'birthday': 679,\n",
              " 'baby': 680,\n",
              " 'arrival': 681,\n",
              " 'web': 682,\n",
              " 'water': 683,\n",
              " 'usairwaysfail': 684,\n",
              " 'totally': 685,\n",
              " 'saw': 686,\n",
              " 'ruin': 687,\n",
              " 'regard': 688,\n",
              " 'ppl': 689,\n",
              " 'plz': 690,\n",
              " 'page': 691,\n",
              " 'notify': 692,\n",
              " 'mobile': 693,\n",
              " 'matter': 694,\n",
              " 'literally': 695,\n",
              " 'lie': 696,\n",
              " 'happening': 697,\n",
              " 'four': 698,\n",
              " 'explanation': 699,\n",
              " 'consider': 700,\n",
              " 'code': 701,\n",
              " 'bna': 702,\n",
              " 'blame': 703,\n",
              " 'bit': 704,\n",
              " 'b': 705,\n",
              " 'area': 706,\n",
              " 'afternoon': 707,\n",
              " 'absolutely': 708,\n",
              " 'train': 709,\n",
              " 'story': 710,\n",
              " 'sound': 711,\n",
              " 'sort': 712,\n",
              " 'saturday': 713,\n",
              " 'program': 714,\n",
              " 'platinum': 715,\n",
              " 'phoenix': 716,\n",
              " 'non': 717,\n",
              " 'news': 718,\n",
              " 'meeting': 719,\n",
              " 'meet': 720,\n",
              " 'meal': 721,\n",
              " 'hire': 722,\n",
              " 'flightd': 723,\n",
              " 'excuse': 724,\n",
              " 'excellent': 725,\n",
              " 'domestic': 726,\n",
              " 'deserve': 727,\n",
              " 'dealing': 728,\n",
              " 'crazy': 729,\n",
              " 'cheap': 730,\n",
              " 'catch': 731,\n",
              " 'behind': 732,\n",
              " 'bank': 733,\n",
              " 'announce': 734,\n",
              " 'advisory': 735,\n",
              " 'accept': 736,\n",
              " 'write': 737,\n",
              " 'warm': 738,\n",
              " 'touch': 739,\n",
              " 'stuff': 740,\n",
              " 'select': 741,\n",
              " 'relations': 742,\n",
              " 'power': 743,\n",
              " 'nope': 744,\n",
              " 'mia': 745,\n",
              " 'itinerary': 746,\n",
              " 'hello': 747,\n",
              " 'feedback': 748,\n",
              " 'feb': 749,\n",
              " 'dollar': 750,\n",
              " 'bother': 751,\n",
              " 'assist': 752,\n",
              " 'apply': 753,\n",
              " 'anyway': 754,\n",
              " 'absolute': 755,\n",
              " 'volume': 756,\n",
              " 'view': 757,\n",
              " 'svc': 758,\n",
              " 'son': 759,\n",
              " 'sister': 760,\n",
              " 'short': 761,\n",
              " 'receipt': 762,\n",
              " 'passbook': 763,\n",
              " 'neveragain': 764,\n",
              " 'mistake': 765,\n",
              " 'keeping': 766,\n",
              " 'item': 767,\n",
              " 'include': 768,\n",
              " 'funeral': 769,\n",
              " 'fl': 770,\n",
              " 'finger': 771,\n",
              " 'damage': 772,\n",
              " 'choose': 773,\n",
              " 'attempt': 774,\n",
              " 'americanairlines': 775,\n",
              " 'window': 776,\n",
              " 'trust': 777,\n",
              " 'tmrw': 778,\n",
              " 'sky': 779,\n",
              " 'safe': 780,\n",
              " 'round': 781,\n",
              " 'reward': 782,\n",
              " 'overhead': 783,\n",
              " 'order': 784,\n",
              " 'offering': 785,\n",
              " 'ny': 786,\n",
              " 'n': 787,\n",
              " 'march': 788,\n",
              " 'hell': 789,\n",
              " 'evening': 790,\n",
              " 'disgust': 791,\n",
              " 'definitely': 792,\n",
              " 'cover': 793,\n",
              " 'conf': 794,\n",
              " 'cc': 795,\n",
              " 'catering': 796,\n",
              " 'captain': 797,\n",
              " 'bs': 798,\n",
              " 'anywhere': 799,\n",
              " 'anymore': 800,\n",
              " 'accommodate': 801,\n",
              " 'worth': 802,\n",
              " 'slow': 803,\n",
              " 'seating': 804,\n",
              " 'rule': 805,\n",
              " 'resolution': 806,\n",
              " 'prefer': 807,\n",
              " 'operate': 808,\n",
              " 'mind': 809,\n",
              " 'locate': 810,\n",
              " 'letting': 811,\n",
              " 'gates': 812,\n",
              " 'fuck': 813,\n",
              " 'frequent': 814,\n",
              " 'folks': 815,\n",
              " 'fit': 816,\n",
              " 'fair': 817,\n",
              " 'except': 818,\n",
              " 'entertainment': 819,\n",
              " 'deplane': 820,\n",
              " 'damn': 821,\n",
              " 'cut': 822,\n",
              " 'clear': 823,\n",
              " 'center': 824,\n",
              " 'become': 825,\n",
              " 'badservice': 826,\n",
              " 'airplane': 827,\n",
              " 'woman': 828,\n",
              " 'willing': 829,\n",
              " 'welcome': 830,\n",
              " 'virgin': 831,\n",
              " 'unhappy': 832,\n",
              " 'text': 833,\n",
              " 'talking': 834,\n",
              " 'takeoff': 835,\n",
              " 'standing': 836,\n",
              " 'special': 837,\n",
              " 'solution': 838,\n",
              " 'single': 839,\n",
              " 'serious': 840,\n",
              " 'save': 841,\n",
              " 'representative': 842,\n",
              " 'remember': 843,\n",
              " 'push': 844,\n",
              " 'pull': 845,\n",
              " 'pathetic': 846,\n",
              " 'party': 847,\n",
              " 'oscar': 848,\n",
              " 'none': 849,\n",
              " 'nightmare': 850,\n",
              " 'mention': 851,\n",
              " 'improve': 852,\n",
              " 'impress': 853,\n",
              " 'ignore': 854,\n",
              " 'honor': 855,\n",
              " 'hanging': 856,\n",
              " 'earn': 857,\n",
              " 'difference': 858,\n",
              " 'department': 859,\n",
              " 'deny': 860,\n",
              " 'delivery': 861,\n",
              " 'count': 862,\n",
              " 'coach': 863,\n",
              " 'clearly': 864,\n",
              " 'callback': 865,\n",
              " 'bird': 866,\n",
              " 'avgeek': 867,\n",
              " 'angry': 868,\n",
              " 'win': 869,\n",
              " 'video': 870,\n",
              " 'useless': 871,\n",
              " 'unbelievable': 872,\n",
              " 'total': 873,\n",
              " 'ta': 874,\n",
              " 'speaking': 875,\n",
              " 'south': 876,\n",
              " 'snack': 877,\n",
              " 'smh': 878,\n",
              " 'result': 879,\n",
              " 'reimburse': 880,\n",
              " 'redeem': 881,\n",
              " 'play': 882,\n",
              " 'photo': 883,\n",
              " 'philadelphia': 884,\n",
              " 'personal': 885,\n",
              " 'per': 886,\n",
              " 'others': 887,\n",
              " 'onboard': 888,\n",
              " 'nonstop': 889,\n",
              " 'mexico': 890,\n",
              " 'merger': 891,\n",
              " 'match': 892,\n",
              " 'iphone': 893,\n",
              " 'game': 894,\n",
              " 'fyi': 895,\n",
              " 'funny': 896,\n",
              " 'foot': 897,\n",
              " 'final': 898,\n",
              " 'fantastic': 899,\n",
              " 'especially': 900,\n",
              " 'enter': 901,\n",
              " 'dept': 902,\n",
              " 'complain': 903,\n",
              " 'clean': 904,\n",
              " 'appear': 905,\n",
              " 'suitcase': 906,\n",
              " 'suggest': 907,\n",
              " 'street': 908,\n",
              " 'stewardess': 909,\n",
              " 'starting': 910,\n",
              " 'security': 911,\n",
              " 'ride': 912,\n",
              " 'require': 913,\n",
              " 'rental': 914,\n",
              " 'realize': 915,\n",
              " 'rate': 916,\n",
              " 'premium': 917,\n",
              " 'premier': 918,\n",
              " 'partner': 919,\n",
              " 'major': 920,\n",
              " 'main': 921,\n",
              " 'likely': 922,\n",
              " 'inflight': 923,\n",
              " 'hand': 924,\n",
              " 'fucking': 925,\n",
              " 'frustration': 926,\n",
              " 'freezing': 927,\n",
              " 'favorite': 928,\n",
              " 'fan': 929,\n",
              " 'exist': 930,\n",
              " 'etc': 931,\n",
              " 'equipment': 932,\n",
              " 'engine': 933,\n",
              " 'diff': 934,\n",
              " 'current': 935,\n",
              " 'crash': 936,\n",
              " 'congrats': 937,\n",
              " 'btw': 938,\n",
              " 'badcustomerservice': 939,\n",
              " 'avoid': 940,\n",
              " 'assign': 941,\n",
              " 'apologize': 942,\n",
              " 'announcement': 943,\n",
              " 'america': 944,\n",
              " 'actual': 945,\n",
              " 'acceptable': 946,\n",
              " 'yep': 947,\n",
              " 'usually': 948,\n",
              " 'uk': 949,\n",
              " 'truly': 950,\n",
              " 'tracking': 951,\n",
              " 'tho': 952,\n",
              " 'sick': 953,\n",
              " 'shot': 954,\n",
              " 'screen': 955,\n",
              " 'reserve': 956,\n",
              " 'relate': 957,\n",
              " 'quickly': 958,\n",
              " 'print': 959,\n",
              " 'onto': 960,\n",
              " 'numbers': 961,\n",
              " 'nc': 962,\n",
              " 'music': 963,\n",
              " 'mileageplus': 964,\n",
              " 'midnight': 965,\n",
              " 'manager': 966,\n",
              " 'manage': 967,\n",
              " 'mad': 968,\n",
              " 'listening': 969,\n",
              " 'level': 970,\n",
              " 'journal': 971,\n",
              " 'intl': 972,\n",
              " 'internet': 973,\n",
              " 'inform': 974,\n",
              " 'impossible': 975,\n",
              " 'girl': 976,\n",
              " 'florida': 977,\n",
              " 'expensive': 978,\n",
              " 'example': 979,\n",
              " 'emergency': 980,\n",
              " 'economy': 981,\n",
              " 'diego': 982,\n",
              " 'couple': 983,\n",
              " 'carrier': 984,\n",
              " 'bus': 985,\n",
              " 'brother': 986,\n",
              " 'bringing': 987,\n",
              " 'ahead': 988,\n",
              " 'advantage': 989,\n",
              " 'within': 990,\n",
              " 'wednesday': 991,\n",
              " 'ways': 992,\n",
              " 'walk': 993,\n",
              " 'visit': 994,\n",
              " 'unhelpful': 995,\n",
              " 'suggestion': 996,\n",
              " 'straight': 997,\n",
              " 'step': 998,\n",
              " 'shock': 999,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUzYe6oEN8jn"
      },
      "source": [
        "**Load Pretrained word embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-57_Rpc6HYhz"
      },
      "source": [
        "Let's download pre-trained GloVe embeddings (a 822M zip file).\n",
        "\n",
        "You'll need to run the following commands:\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "!unzip -q glove.6B.zip\n",
        "\n",
        "The archive contains text-encoded vectors of various sizes: 50-dimensional, 100-dimensional, 200-dimensional, 300-dimensional. We'll use the 100D ones.\n",
        "\n",
        "Let's make a dict mapping words (strings) to their NumPy vector representation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A42hqlU5cGKj",
        "outputId": "626e2286-3443-4f04-fcec-86d4fbe4c4d6"
      },
      "source": [
        "path_to_glove_file = \"/content/drive/MyDrive/NLP Data Sets/glove.6B.100d.txt\"\n",
        "print (path_to_glove_file)\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NLP Data Sets/glove.6B.100d.txt\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMd2bK0XHgH2"
      },
      "source": [
        "Prepare a corresponding embedding matrix that we can use in a Keras Embedding layer. \n",
        "\n",
        "It's a simple NumPy matrix where entry at index i is the pre-trained vector for the word of index i in our vectorizer's vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZZzKo8ucGM8",
        "outputId": "7a174523-2646-4500-a1bf-1aa0c2b62a96"
      },
      "source": [
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 6474 words (1645 misses)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEQdfw0HfkIL"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhiWWK6LOEfj"
      },
      "source": [
        "# **Build the different models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buovz6HIfuSI"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvN3mciFfnh-"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "def build_regression():\n",
        "    model = Sequential()\n",
        "    model.add(layers.Input(shape=(200,), dtype=\"int64\"))\n",
        "    model.add(embedding_layer)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(N_CLASSES, activation=\"softmax\", name='OutputLayer'))\n",
        "    \n",
        "    model.compile(\n",
        "                optimizer='rmsprop',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    #logReg.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0Hui54rfy5e"
      },
      "source": [
        "**MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMSk4bSMfnnC"
      },
      "source": [
        "def build_mlp128(hidden_size=128):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Input(shape=(200,), dtype=\"int64\"))\n",
        "    model.add(embedding_layer)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(hidden_size))\n",
        "    model.add(layers.Dense(N_CLASSES, activation=\"softmax\", name='OutputLayer'))\n",
        "    \n",
        "    model.compile(\n",
        "                optimizer='rmsprop',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqfVG6Zji1EW"
      },
      "source": [
        "def build_mlp30(hidden_size=30):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Input(shape=(200,), dtype=\"int64\"))\n",
        "    model.add(embedding_layer)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(hidden_size))\n",
        "    model.add(layers.Dense(N_CLASSES, activation=\"softmax\", name='OutputLayer'))\n",
        "    \n",
        "    model.compile(\n",
        "                optimizer='rmsprop',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdz81d0pHMrt"
      },
      "source": [
        "**CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpbux7rEHQkN"
      },
      "source": [
        "def build_cnn():\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(layers.Input(shape=(200,), dtype=\"int64\"))\n",
        "    model.add(embedding_layer)\n",
        "    model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(N_CLASSES, activation=\"softmax\", name='OutputLayer')) \n",
        "    \n",
        "    # compile network\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In_Sy8KlCczT"
      },
      "source": [
        "def build_LSTM():\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(layers.Input(shape=(200,), dtype=\"int64\"))\n",
        "    model.add(embedding_layer)\n",
        "    model.add(LSTM(100))\n",
        "    model.add(layers.Dense(N_CLASSES, activation=\"softmax\", name='OutputLayer'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxzuXCigf2T7"
      },
      "source": [
        "**Wrap the keras in code to sklearn**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VwDQhVrfnp4"
      },
      "source": [
        "NUM_EPOCHS = 1 # You can change the number of epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ2a4lK8fnse"
      },
      "source": [
        "reg = tf.keras.wrappers.scikit_learn.KerasClassifier(\n",
        "                            build_regression,\n",
        "                            epochs=NUM_EPOCHS,\n",
        "                            verbose=False)\n",
        "reg._estimator_type = \"classifier\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz3N6o6FfnvM"
      },
      "source": [
        "mlp128 = tf.keras.wrappers.scikit_learn.KerasClassifier(\n",
        "                            build_mlp128,\n",
        "                            epochs=NUM_EPOCHS,\n",
        "                            verbose=False)\n",
        "mlp128._estimator_type = \"classifier\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBH5INDUfnxj"
      },
      "source": [
        "mlp30 = tf.keras.wrappers.scikit_learn.KerasClassifier(\n",
        "                            build_mlp30,\n",
        "                            epochs=NUM_EPOCHS,\n",
        "                            verbose=False)\n",
        "mlp30._estimator_type = \"classifier\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HA_skghHkdK"
      },
      "source": [
        "cnn = tf.keras.wrappers.scikit_learn.KerasClassifier(\n",
        "                            build_cnn,\n",
        "                            epochs=NUM_EPOCHS,\n",
        "                            verbose=False)\n",
        "cnn._estimator_type = \"classifier\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJn9prTYq9mn"
      },
      "source": [
        "lstm = tf.keras.wrappers.scikit_learn.KerasClassifier(\n",
        "                            build_LSTM,\n",
        "                            epochs=NUM_EPOCHS,\n",
        "                            verbose=False)\n",
        "lstm._estimator_type = \"classifier\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4rKe_HQOTGr"
      },
      "source": [
        "# **Model ensemble: combine different classification models, add your classifiers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NteBVqjnfnze"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "voting = VotingClassifier(\n",
        "             estimators=[('mlp128', mlp128),\n",
        "                         ('mlp30', mlp30),\n",
        "                         ('reg', reg),\n",
        "                         ('cnn', cnn),\n",
        "                         ('lstm', lstm)], \n",
        "             voting='soft',\n",
        "             flatten_transform=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srD7DpylgEE7",
        "outputId": "c35d2759-7a4f-4e9e-c388-5ccbd5c14429"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                              good thank \n",
              "1        way ruin vacation brother call night multiple ...\n",
              "2        yes thankfully catering get loading frustrate ...\n",
              "3        automate message helpful impossible speak huma...\n",
              "4         makingloveoutofnothingatall brandloveaffair lax \n",
              "                               ...                        \n",
              "11853    help us phone gate checkin book travel client ...\n",
              "11854    worst customer service line call times today a...\n",
              "11855    grade trip flight timeliness cancel flightatio...\n",
              "11856             thanks vague can response address issue \n",
              "11857    already airport hr late flightr still guy real...\n",
              "Name: text, Length: 11858, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2LGho3JHvNY"
      },
      "source": [
        "# **Train the models**\n",
        "\n",
        "First, convert our list-of-strings data to NumPy arrays of integer indices. The arrays\n",
        "are right-padded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d2j8pEWgEKS"
      },
      "source": [
        "# prepare training data\n",
        "x_train_prep = vectorizer(np.array([[s] for s in x_train])).numpy()\n",
        "x_dev_prep = vectorizer(np.array([[s] for s in x_dev])).numpy()\n",
        "x_test_prep = vectorizer(np.array([[s] for s in x_test])).numpy()\n",
        "\n",
        "y_train_prep = np.array(y_train)\n",
        "y_dev_prep = np.array(y_dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPErvE-M1cx1",
        "outputId": "d76b15e4-7e27-45e9-92c4-d004c6230aed"
      },
      "source": [
        "print(y_train_prep)\n",
        "print(y_dev_prep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 0 2 ... 0 0 0]\n",
            "[2 2 0 ... 0 0 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k5pJcOWgEMi",
        "outputId": "83168656-fba7-4e6d-c337-95d01c9b557a"
      },
      "source": [
        "voting.fit(x_train_prep, y_train_prep) # training in sklearn \n",
        "reg.fit(x_train_prep, y_train_prep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe50910a150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-RBuuZlgEPL",
        "outputId": "34e05104-690d-4ed6-f6da-660f28f4d732"
      },
      "source": [
        "mlp128.fit(x_train_prep, y_train_prep) # training in sklearn \n",
        "mlp30.fit(x_train_prep, y_train_prep)\n",
        "cnn.fit(x_train_prep, y_train_prep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe508d25150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKqbEwfygERa",
        "outputId": "79b4dfca-720c-40f2-9847-284a07d66b97"
      },
      "source": [
        "# training in Keras directly \n",
        "reg_keras=build_regression()\n",
        "reg_keras.fit(x_train_prep, y_train_prep, batch_size=128, epochs=20, validation_data=(x_dev_prep, y_dev_prep))\n",
        "# prediction\n",
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "reg_preds = reg_keras(x)\n",
        "reg_end_to_end_model = keras.Model(string_input, reg_preds)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "93/93 [==============================] - 2s 15ms/step - loss: 0.8765 - accuracy: 0.6425 - val_loss: 0.7204 - val_accuracy: 0.7215\n",
            "Epoch 2/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.6599 - accuracy: 0.7369 - val_loss: 0.6851 - val_accuracy: 0.7284\n",
            "Epoch 3/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.6150 - accuracy: 0.7475 - val_loss: 0.6731 - val_accuracy: 0.7307\n",
            "Epoch 4/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.5944 - accuracy: 0.7528 - val_loss: 0.6715 - val_accuracy: 0.7291\n",
            "Epoch 5/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.5697 - accuracy: 0.7654 - val_loss: 0.6656 - val_accuracy: 0.7314\n",
            "Epoch 6/20\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 0.5606 - accuracy: 0.7676 - val_loss: 0.6665 - val_accuracy: 0.7299\n",
            "Epoch 7/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.5439 - accuracy: 0.7727 - val_loss: 0.6646 - val_accuracy: 0.7291\n",
            "Epoch 8/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.5428 - accuracy: 0.7753 - val_loss: 0.6679 - val_accuracy: 0.7238\n",
            "Epoch 9/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.5354 - accuracy: 0.7763 - val_loss: 0.6716 - val_accuracy: 0.7291\n",
            "Epoch 10/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.5256 - accuracy: 0.7842 - val_loss: 0.6731 - val_accuracy: 0.7253\n",
            "Epoch 11/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.5244 - accuracy: 0.7858 - val_loss: 0.6760 - val_accuracy: 0.7132\n",
            "Epoch 12/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.5239 - accuracy: 0.7846 - val_loss: 0.6819 - val_accuracy: 0.7215\n",
            "Epoch 13/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.5071 - accuracy: 0.7923 - val_loss: 0.6872 - val_accuracy: 0.7140\n",
            "Epoch 14/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.5014 - accuracy: 0.7936 - val_loss: 0.6928 - val_accuracy: 0.7178\n",
            "Epoch 15/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.5067 - accuracy: 0.7893 - val_loss: 0.6957 - val_accuracy: 0.7132\n",
            "Epoch 16/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.5049 - accuracy: 0.7925 - val_loss: 0.7027 - val_accuracy: 0.7200\n",
            "Epoch 17/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.4934 - accuracy: 0.8018 - val_loss: 0.6992 - val_accuracy: 0.7170\n",
            "Epoch 18/20\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 0.4953 - accuracy: 0.7952 - val_loss: 0.7014 - val_accuracy: 0.7170\n",
            "Epoch 19/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.4962 - accuracy: 0.7952 - val_loss: 0.7043 - val_accuracy: 0.7200\n",
            "Epoch 20/20\n",
            "93/93 [==============================] - 1s 13ms/step - loss: 0.5071 - accuracy: 0.7916 - val_loss: 0.7140 - val_accuracy: 0.7132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-TsLbDNKn3Y",
        "outputId": "e8c41883-d260-4b07-e746-937e7ba28a5e"
      },
      "source": [
        "# training in Keras directly \n",
        "mlp128_keras=build_mlp128()\n",
        "mlp128_keras.fit(x_train_prep, y_train_prep, batch_size=128, epochs=20, validation_data=(x_dev_prep, y_dev_prep))\n",
        "# prediction\n",
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "mlp128_preds = mlp128_keras(x)\n",
        "mlp128_end_to_end_model = keras.Model(string_input, mlp128_preds)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.8662 - accuracy: 0.6536 - val_loss: 0.6947 - val_accuracy: 0.7071\n",
            "Epoch 2/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.6255 - accuracy: 0.7446 - val_loss: 0.6754 - val_accuracy: 0.7200\n",
            "Epoch 3/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.5711 - accuracy: 0.7618 - val_loss: 0.7080 - val_accuracy: 0.7185\n",
            "Epoch 4/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.5595 - accuracy: 0.7685 - val_loss: 0.7239 - val_accuracy: 0.7185\n",
            "Epoch 5/20\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.5520 - accuracy: 0.7695 - val_loss: 0.7080 - val_accuracy: 0.7056\n",
            "Epoch 6/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.5334 - accuracy: 0.7761 - val_loss: 0.7695 - val_accuracy: 0.7140\n",
            "Epoch 7/20\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.5350 - accuracy: 0.7726 - val_loss: 0.7314 - val_accuracy: 0.7056\n",
            "Epoch 8/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.5290 - accuracy: 0.7758 - val_loss: 0.7519 - val_accuracy: 0.7041\n",
            "Epoch 9/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.5148 - accuracy: 0.7893 - val_loss: 0.7275 - val_accuracy: 0.7018\n",
            "Epoch 10/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.5033 - accuracy: 0.7951 - val_loss: 0.7456 - val_accuracy: 0.6912\n",
            "Epoch 11/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.5134 - accuracy: 0.7860 - val_loss: 0.7589 - val_accuracy: 0.6942\n",
            "Epoch 12/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.5013 - accuracy: 0.7897 - val_loss: 0.7622 - val_accuracy: 0.7200\n",
            "Epoch 13/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.4946 - accuracy: 0.7939 - val_loss: 0.7565 - val_accuracy: 0.7011\n",
            "Epoch 14/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.4876 - accuracy: 0.7985 - val_loss: 0.7632 - val_accuracy: 0.7071\n",
            "Epoch 15/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.5007 - accuracy: 0.7950 - val_loss: 0.7761 - val_accuracy: 0.7003\n",
            "Epoch 16/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.5051 - accuracy: 0.7889 - val_loss: 0.8082 - val_accuracy: 0.6973\n",
            "Epoch 17/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.4900 - accuracy: 0.7974 - val_loss: 0.8082 - val_accuracy: 0.7071\n",
            "Epoch 18/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.4839 - accuracy: 0.7991 - val_loss: 0.7702 - val_accuracy: 0.7079\n",
            "Epoch 19/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.4848 - accuracy: 0.8041 - val_loss: 0.7799 - val_accuracy: 0.6988\n",
            "Epoch 20/20\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.4795 - accuracy: 0.8007 - val_loss: 0.7856 - val_accuracy: 0.6866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx05fFhbKn8_",
        "outputId": "58feeb28-ebb0-4b29-c1f2-294619dd3a62"
      },
      "source": [
        "# training in Keras directly \n",
        "mlp30_keras=build_mlp30()\n",
        "mlp30_keras.fit(x_train_prep, y_train_prep, batch_size=128, epochs=20, validation_data=(x_dev_prep, y_dev_prep))\n",
        "# prediction\n",
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "mlp30_preds = mlp30_keras(x)\n",
        "mlp30_end_to_end_model = keras.Model(string_input, mlp30_preds)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.8315 - accuracy: 0.6553 - val_loss: 0.7361 - val_accuracy: 0.6844\n",
            "Epoch 2/20\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.6164 - accuracy: 0.7430 - val_loss: 0.6803 - val_accuracy: 0.7132\n",
            "Epoch 3/20\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.5716 - accuracy: 0.7686 - val_loss: 0.6995 - val_accuracy: 0.7215\n",
            "Epoch 4/20\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.5607 - accuracy: 0.7684 - val_loss: 0.7187 - val_accuracy: 0.7086\n",
            "Epoch 5/20\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.5381 - accuracy: 0.7770 - val_loss: 0.7186 - val_accuracy: 0.7132\n",
            "Epoch 6/20\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.5230 - accuracy: 0.7841 - val_loss: 0.7297 - val_accuracy: 0.7170\n",
            "Epoch 7/20\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.5254 - accuracy: 0.7867 - val_loss: 0.7283 - val_accuracy: 0.7132\n",
            "Epoch 8/20\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.5078 - accuracy: 0.7894 - val_loss: 0.7475 - val_accuracy: 0.7178\n",
            "Epoch 9/20\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.5135 - accuracy: 0.7842 - val_loss: 0.7495 - val_accuracy: 0.7102\n",
            "Epoch 10/20\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.5090 - accuracy: 0.7897 - val_loss: 0.7457 - val_accuracy: 0.7018\n",
            "Epoch 11/20\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.5063 - accuracy: 0.7901 - val_loss: 0.7931 - val_accuracy: 0.6980\n",
            "Epoch 12/20\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.5090 - accuracy: 0.7930 - val_loss: 0.7773 - val_accuracy: 0.6950\n",
            "Epoch 13/20\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.5044 - accuracy: 0.7979 - val_loss: 0.7610 - val_accuracy: 0.7003\n",
            "Epoch 14/20\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.4955 - accuracy: 0.7967 - val_loss: 0.7932 - val_accuracy: 0.6889\n",
            "Epoch 15/20\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.4938 - accuracy: 0.7916 - val_loss: 0.7807 - val_accuracy: 0.6912\n",
            "Epoch 16/20\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.4870 - accuracy: 0.7983 - val_loss: 0.7901 - val_accuracy: 0.7033\n",
            "Epoch 17/20\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.4993 - accuracy: 0.7988 - val_loss: 0.7966 - val_accuracy: 0.7086\n",
            "Epoch 18/20\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.4902 - accuracy: 0.8015 - val_loss: 0.8047 - val_accuracy: 0.6866\n",
            "Epoch 19/20\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.4854 - accuracy: 0.8002 - val_loss: 0.7976 - val_accuracy: 0.6988\n",
            "Epoch 20/20\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.4712 - accuracy: 0.8056 - val_loss: 0.8067 - val_accuracy: 0.6866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JQ8ZrS8KoCS",
        "outputId": "b7b64a88-2990-4f9d-92b7-4dc8dc379145"
      },
      "source": [
        "# training in Keras directly \n",
        "cnn_keras=build_cnn()\n",
        "cnn_keras.fit(x_train_prep, y_train_prep, batch_size=128, epochs=20, validation_data=(x_dev_prep, y_dev_prep))\n",
        "# prediction\n",
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "cnn_preds = cnn_keras(x)\n",
        "cnn_end_to_end_model = keras.Model(string_input, cnn_preds)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "93/93 [==============================] - 10s 102ms/step - loss: 0.8861 - accuracy: 0.6338 - val_loss: 0.7160 - val_accuracy: 0.7185\n",
            "Epoch 2/20\n",
            "93/93 [==============================] - 9s 100ms/step - loss: 0.6519 - accuracy: 0.7369 - val_loss: 0.6571 - val_accuracy: 0.7231\n",
            "Epoch 3/20\n",
            "93/93 [==============================] - 9s 100ms/step - loss: 0.5775 - accuracy: 0.7651 - val_loss: 0.6568 - val_accuracy: 0.7246\n",
            "Epoch 4/20\n",
            "93/93 [==============================] - 9s 100ms/step - loss: 0.5368 - accuracy: 0.7811 - val_loss: 0.6636 - val_accuracy: 0.7094\n",
            "Epoch 5/20\n",
            "93/93 [==============================] - 9s 100ms/step - loss: 0.5195 - accuracy: 0.7870 - val_loss: 0.6259 - val_accuracy: 0.7436\n",
            "Epoch 6/20\n",
            "93/93 [==============================] - 9s 101ms/step - loss: 0.4851 - accuracy: 0.8046 - val_loss: 0.6306 - val_accuracy: 0.7322\n",
            "Epoch 7/20\n",
            "93/93 [==============================] - 9s 100ms/step - loss: 0.4586 - accuracy: 0.8195 - val_loss: 0.6392 - val_accuracy: 0.7405\n",
            "Epoch 8/20\n",
            "93/93 [==============================] - 9s 101ms/step - loss: 0.4290 - accuracy: 0.8284 - val_loss: 0.6869 - val_accuracy: 0.6958\n",
            "Epoch 9/20\n",
            "93/93 [==============================] - 9s 100ms/step - loss: 0.4036 - accuracy: 0.8435 - val_loss: 0.6477 - val_accuracy: 0.7299\n",
            "Epoch 10/20\n",
            "93/93 [==============================] - 9s 100ms/step - loss: 0.3755 - accuracy: 0.8588 - val_loss: 0.6653 - val_accuracy: 0.7276\n",
            "Epoch 11/20\n",
            "93/93 [==============================] - 9s 100ms/step - loss: 0.3534 - accuracy: 0.8664 - val_loss: 0.6691 - val_accuracy: 0.7147\n",
            "Epoch 12/20\n",
            "93/93 [==============================] - 9s 101ms/step - loss: 0.3391 - accuracy: 0.8729 - val_loss: 0.6790 - val_accuracy: 0.7344\n",
            "Epoch 13/20\n",
            "93/93 [==============================] - 9s 100ms/step - loss: 0.3197 - accuracy: 0.8792 - val_loss: 0.6918 - val_accuracy: 0.7193\n",
            "Epoch 14/20\n",
            "93/93 [==============================] - 9s 101ms/step - loss: 0.3004 - accuracy: 0.8935 - val_loss: 0.7242 - val_accuracy: 0.7071\n",
            "Epoch 15/20\n",
            "93/93 [==============================] - 9s 101ms/step - loss: 0.2885 - accuracy: 0.8966 - val_loss: 0.7773 - val_accuracy: 0.6768\n",
            "Epoch 16/20\n",
            "93/93 [==============================] - 9s 101ms/step - loss: 0.2662 - accuracy: 0.9087 - val_loss: 0.7388 - val_accuracy: 0.7071\n",
            "Epoch 17/20\n",
            "93/93 [==============================] - 9s 101ms/step - loss: 0.2579 - accuracy: 0.9112 - val_loss: 0.7432 - val_accuracy: 0.7322\n",
            "Epoch 18/20\n",
            "93/93 [==============================] - 9s 101ms/step - loss: 0.2390 - accuracy: 0.9228 - val_loss: 0.8239 - val_accuracy: 0.7360\n",
            "Epoch 19/20\n",
            "93/93 [==============================] - 9s 101ms/step - loss: 0.2140 - accuracy: 0.9324 - val_loss: 0.7781 - val_accuracy: 0.7056\n",
            "Epoch 20/20\n",
            "93/93 [==============================] - 9s 102ms/step - loss: 0.2025 - accuracy: 0.9364 - val_loss: 0.7941 - val_accuracy: 0.7299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz4vnmvRDoDT",
        "outputId": "01481c03-30cc-4fe0-afb7-a4864ad8e154"
      },
      "source": [
        "lstm_keras=build_LSTM()\n",
        "lstm_keras.fit(x_train_prep, y_train_prep, batch_size=128, epochs=20, validation_data=(x_dev_prep, y_dev_prep))\n",
        "# prediction\n",
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "lstm_preds = lstm_keras(x)\n",
        "lstm_end_to_end_model = keras.Model(string_input, lstm_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "93/93 [==============================] - 42s 425ms/step - loss: 1.0681 - accuracy: 0.6271 - val_loss: 0.9231 - val_accuracy: 0.6267\n",
            "Epoch 2/20\n",
            "93/93 [==============================] - 39s 419ms/step - loss: 0.9322 - accuracy: 0.6190 - val_loss: 0.9181 - val_accuracy: 0.6267\n",
            "Epoch 3/20\n",
            "93/93 [==============================] - 39s 415ms/step - loss: 0.9142 - accuracy: 0.6318 - val_loss: 0.9230 - val_accuracy: 0.6267\n",
            "Epoch 4/20\n",
            "93/93 [==============================] - 38s 413ms/step - loss: 0.9219 - accuracy: 0.6239 - val_loss: 0.9254 - val_accuracy: 0.6267\n",
            "Epoch 5/20\n",
            "93/93 [==============================] - 38s 413ms/step - loss: 0.9199 - accuracy: 0.6263 - val_loss: 0.9208 - val_accuracy: 0.6267\n",
            "Epoch 6/20\n",
            "93/93 [==============================] - 39s 415ms/step - loss: 0.9165 - accuracy: 0.6287 - val_loss: 0.9172 - val_accuracy: 0.6267\n",
            "Epoch 7/20\n",
            "93/93 [==============================] - 39s 416ms/step - loss: 0.9273 - accuracy: 0.6192 - val_loss: 0.9182 - val_accuracy: 0.6267\n",
            "Epoch 8/20\n",
            "93/93 [==============================] - 39s 416ms/step - loss: 0.9200 - accuracy: 0.6259 - val_loss: 0.9186 - val_accuracy: 0.6267\n",
            "Epoch 9/20\n",
            "93/93 [==============================] - 39s 417ms/step - loss: 0.9160 - accuracy: 0.6278 - val_loss: 0.9165 - val_accuracy: 0.6267\n",
            "Epoch 10/20\n",
            "93/93 [==============================] - 39s 419ms/step - loss: 0.9173 - accuracy: 0.6268 - val_loss: 0.9172 - val_accuracy: 0.6267\n",
            "Epoch 11/20\n",
            "93/93 [==============================] - 39s 417ms/step - loss: 0.9197 - accuracy: 0.6255 - val_loss: 0.9164 - val_accuracy: 0.6267\n",
            "Epoch 12/20\n",
            "93/93 [==============================] - 39s 417ms/step - loss: 0.9131 - accuracy: 0.6309 - val_loss: 0.9167 - val_accuracy: 0.6267\n",
            "Epoch 13/20\n",
            "93/93 [==============================] - 39s 414ms/step - loss: 0.9159 - accuracy: 0.6275 - val_loss: 0.9169 - val_accuracy: 0.6267\n",
            "Epoch 14/20\n",
            "93/93 [==============================] - 39s 415ms/step - loss: 0.9216 - accuracy: 0.6226 - val_loss: 0.9172 - val_accuracy: 0.6267\n",
            "Epoch 15/20\n",
            "93/93 [==============================] - 39s 418ms/step - loss: 0.9137 - accuracy: 0.6306 - val_loss: 0.9172 - val_accuracy: 0.6267\n",
            "Epoch 16/20\n",
            "93/93 [==============================] - 39s 416ms/step - loss: 0.9199 - accuracy: 0.6234 - val_loss: 0.9181 - val_accuracy: 0.6267\n",
            "Epoch 17/20\n",
            "93/93 [==============================] - 39s 416ms/step - loss: 0.9101 - accuracy: 0.6312 - val_loss: 0.9212 - val_accuracy: 0.6267\n",
            "Epoch 18/20\n",
            "93/93 [==============================] - 38s 412ms/step - loss: 0.9207 - accuracy: 0.6247 - val_loss: 0.9216 - val_accuracy: 0.6267\n",
            "Epoch 19/20\n",
            "93/93 [==============================] - 39s 417ms/step - loss: 0.9195 - accuracy: 0.6257 - val_loss: 0.9175 - val_accuracy: 0.6267\n",
            "Epoch 20/20\n",
            "93/93 [==============================] - 39s 421ms/step - loss: 0.9214 - accuracy: 0.6217 - val_loss: 0.9163 - val_accuracy: 0.6267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg4AQLz6H-CL"
      },
      "source": [
        "# **predict the results for each model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeJd73JOhSo4",
        "outputId": "f86a3cc8-8487-468c-8b22-ca3a895b44c1"
      },
      "source": [
        "y_dev_pred_reg = reg.predict(x_dev_prep)\n",
        "y_dev_pred_mlp128 = mlp128.predict(x_dev_prep)\n",
        "y_dev_pred_mlp30 = mlp30.predict(x_dev_prep)\n",
        "y_dev_pred_voting = voting.predict(x_dev_prep)\n",
        "y_dev_pred_cnn = cnn.predict(x_dev_prep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "5peqV9wYhSsA",
        "outputId": "175351a0-8214-4d47-ce3a-4fb5efc40422"
      },
      "source": [
        "plt.figure\n",
        "f1_reg = f1_score(y_dev, y_dev_pred_reg, average='micro')\n",
        "f1_mlp128 = f1_score(y_dev, y_dev_pred_mlp128, average='micro')\n",
        "f1_mlp30 = f1_score(y_dev, y_dev_pred_mlp30, average='micro')\n",
        "f1_cnn = f1_score(y_dev, y_dev_pred_cnn, average='micro')\n",
        "f1_voting = f1_score(y_dev, y_dev_pred_voting, average=None)\n",
        "\n",
        "f1s = [f1_voting, f1_reg, f1_mlp128, f1_mlp30, f1_cnn]\n",
        "model_names = ['Voting', 'reg', 'MLP128', 'mlp30', 'cnn']\n",
        "for i in range(len(model_names)):\n",
        "    f1 = f1s[i]\n",
        "    model_name = model_names[i]\n",
        "    plt.bar(model_name, f1)\n",
        "\n",
        "\n",
        "\n",
        "plt.xlabel('Model names')\n",
        "plt.ylabel('F1 score')\n",
        "plt.title('F1 score for each model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'F1 score for each model')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUi-6qLbhh5m"
      },
      "source": [
        "# Predict the test set \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nBM4ltWhSu3",
        "outputId": "d081ff70-736e-45f4-f565-cf1c1e298b77"
      },
      "source": [
        "y_pred = voting.predict(x_test_prep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0gI1veqhSxs",
        "outputId": "e0fcb59e-5374-4e54-810e-84365a954bff"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 2, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW99Z-K2hS2U"
      },
      "source": [
        "pred_labels = le.inverse_transform(y_pred)\n",
        "test['airline_sentiment'] = pred_labels\n",
        "test.to_csv('test.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "TJpBFgDyhS5Y",
        "outputId": "dc735748-1f6b-45d3-a424-317b7ee94b24"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570251814970515456</td>\n",
              "      <td>@AmericanAir I need refund.</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>568173388663013377</td>\n",
              "      <td>@USAirways after 3 Cancelled Flightlations and...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>569320520728113152</td>\n",
              "      <td>@JetBlue thanks so much. Can't wait to fly wit...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>569503367757754369</td>\n",
              "      <td>@united I have never been more frustrated than...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>568981079278751744</td>\n",
              "      <td>@USAirways - the worst! Hold time crazy, agent...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>569678153783877634</td>\n",
              "      <td>@AmericanAir I didn't miss my flight.  America...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1460</th>\n",
              "      <td>569882442129133568</td>\n",
              "      <td>@USAirways here's to sitting on hold for 4 hrs...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1461</th>\n",
              "      <td>568192010789777408</td>\n",
              "      <td>@SouthwestAir just had a great flight #4223 wi...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1462</th>\n",
              "      <td>569774692371820544</td>\n",
              "      <td>@AmericanAir Why did  AA973 return to JFK? Tha...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1463</th>\n",
              "      <td>569940582572945409</td>\n",
              "      <td>@AmericanAir How can I get a flight change whi...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1464 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                tweet_id  ... airline_sentiment\n",
              "0     570251814970515456  ...          negative\n",
              "1     568173388663013377  ...          negative\n",
              "2     569320520728113152  ...          negative\n",
              "3     569503367757754369  ...          negative\n",
              "4     568981079278751744  ...          negative\n",
              "...                  ...  ...               ...\n",
              "1459  569678153783877634  ...          negative\n",
              "1460  569882442129133568  ...          negative\n",
              "1461  568192010789777408  ...          positive\n",
              "1462  569774692371820544  ...          negative\n",
              "1463  569940582572945409  ...          negative\n",
              "\n",
              "[1464 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNw3uxDDhS8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a46be18-85f8-45b4-f560-c9d8a8c7a471"
      },
      "source": [
        "test['airline_sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    1274\n",
              "positive     121\n",
              "neutral       69\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMrv6sP6rRCc"
      },
      "source": [
        "# **References and citations**\n",
        "scikit-learn  1.11.6. Voting Classifier https://scikit-learn.org/stable/modules/ensemble.html \n",
        "\n",
        "Keras word embeddings: https://keras.io/examples/nlp/pretrained_word_embeddings/ \n",
        "\n",
        "Keras models with scikit learn: https://www.kaggle.com/residentmario/using-keras-models-with-scikit-learn-pipelines\n",
        "\n",
        "Practical 3, which feature is helpful for female name classification. https://www.nltk.org/book/ch06.html\n",
        "\n",
        "research paper: https://github.com/yoonkim/CNN_sentence\n",
        "\n",
        "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html \n",
        "\n",
        "https://www.nltk.org/book/ch06.html \n",
        "\n",
        "Other online resources: \n",
        "\n",
        "https://towardsdatascience.com/setting-up-text-preprocessing-pipeline-using-scikit-learn-and-spacy-e09b9b76758f\n",
        "\n",
        "how to encode text data https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/#:~:text=The%20CountVectorizer%20provides%20a%20simple,can%20use%20it%20as%20follows%3A&text=Call%20the%20transform()%20function,encode%20each%20as%20a%20vector.\n",
        "\n",
        "cnn model: https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/\n",
        "\n",
        "lstm model: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"
      ]
    }
  ]
}